\documentclass{article}

%\usepackage{caption}

\renewcommand{\thesubsection}{\thesection.\alph{subsection}}

\usepackage{graphicx}
\usepackage{caption}
\usepackage{float}
\usepackage{amsmath}
\usepackage{forest}
\usepackage{multicol}
\usepackage[margin=1.1in]{geometry}
\usepackage{cancel}
\usepackage{tabularx}

\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=left,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=4
}

\begin{document}
\title{Comp 6721 - Artificial Intelligence - Project 2 project report}
\author{Federico O'Reilly Regueiro - 40012304}
\date{December 7th, 2016}
\maketitle

%------------------------ Q1 ------------------------%
\section{Goal-stack planning}
\subsection{problems with the representation?}
$MOVE(B,A,Table)$ collides with $MOVE-TO-TABLE(B, A)$ and generates an inconsistent knowledge-base as well as
having silly preconditions such as $Clear(Table)$ which could potentially make it impossible to move a block from the 
$Table$ and place it atop another block. Additionally, $MOVE(B, C, C)$  could display inconsistent behavior.

The table can hold many  blocks and therefore should be treated differently from blocks.
So another problem stems from the fact that  the predicate $On(x)$ should not take $Table$, instead, we need another 
predicate $OnTable(x)$ as well as an operation to move a block from the table atop another empty block, a predicate $Block(x)$ 
that becomes a precondition to $Move(b, x, y)$ (added preconditions: $Block(x) \land Block(y)$ and $\lnot(x = y)$).

\subsection{Demonstrate goal-stack planning}
%\begin{multicols}{2}
\begin{enumerate}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
   	\setlength{\parsep}{0pt} 
   	
	\item{\begin{tabularx}{\textwidth}{ X X X } 
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
		$OnTable(A)$ 	& 							& $On(B, C)$\\  	
		$On(B,A)$		& 							& $OnTable(A)$\\	
		$On(C,B)$		& 							& $Clear(B)$\\					
		 					& 							& $Clear(A)$\\
		 					& 							& $OnTable(C)$\\
	\end{tabularx}}
	\item{\begin{tabularx}{\textwidth}{ X X X }  
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
		 					& $OnTable(A)$			& $On(B, C)$\\  	
		$On(B,A)$		& 							& $OnTable(A)$\\	
		$On(C,B)$		& 							& $Clear(B)$\\					
		 					& 							& $Clear(A)$\\
		 					& 							& $OnTable(C)$\\		 					
	\end{tabularx}}
	\item{\begin{tabularx}{\textwidth}{ X X X }  
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
		 $MOVE(B, C, A)$& 							& $On(B, C)$\\  	
		$On(B,A)$		& 							& $OnTable(A)$\\	
		$On(C,B)$		& 							& $Clear(B)$\\					
		 					& 							& $Clear(A)$\\
		 					& 							& $OnTable(C)$\\		 							
	\end{tabularx}}
	\item{\begin{tabularx}{\textwidth}{ X X X }  
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
		 $On(B,C)$		& 							& $On(B, C)$\\  	
		 $Clear(A)$		& 							& $OnTable(A)$\\	
		 $Clear(B)$		& 							& $Clear(B)$\\					
		 $MOVE(B, C, A)$& 							& $Clear(A)$\\		
		 $On(B,A)$		& 							& $OnTable(C)$\\	
		 $On(C,B)$		& 							& \\			 							 					
	\end{tabularx}}
	\item{\begin{tabularx}{\textwidth}{ X X X }  
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
		$Move(B, C, A)$& 	$On(B,C)$			& $On(B, C)$\\  	
		$On(B,A)$		& 	$Clear(A)$			& $OnTable(A)$\\	
		$On(C,B)$		& 	$Clear(B)$			& $Clear(B)$\\					
		 					& 							& $Clear(A)$\\	
		 					& 							& $OnTable(C)$\\		 						
	\end{tabularx}}
	\item{\begin{tabularx}{\textwidth}{ X X X }  
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
		 					& 	$MOVE(B, C, A)$	& $\cancel{On(B, C)}$\\  	
		$On(B,A)$		& 							& $OnTable(A)$\\	
		$On(C,B)$		& 							& $Clear(B)$\\					
		 					& 							& $\cancel{Clear(A)}$\\		
		 					& 							& $On(B, A)$\\		 					
		 					& 							& $Clear(C)$\\
		 					& 							& $OnTable(C)$\\		 					
	\end{tabularx}}
	\item{\begin{tabularx}{\textwidth}{ X X X }  
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
		 $MOVE(C, Table, B)$& $On(B,A)$		& $Clear(C)$\\  	
		$On(C,B)$		& 							& $OnTable(A)$\\	
							& 							& $Clear(B)$\\					
		 					& 							& $On(B, A)$\\	
		 					& 							& $OnTable(C)$\\		 						
	\end{tabularx}}
	\item{\begin{tabularx}{\textwidth}{ X X X }  
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
		$OnTable(C)$	& 							& $Clear(C)$\\  	
		$Clear(C)$		& 							& $OnTable(A)$\\	
		$Clear(B)$		& 							& $Clear(B)$\\					
		$MOVE(C, Table, A)$&						& $On(B, A)$\\	
		$On(C,B)$		& 							& $OnTable(C)$\\		 						
	\end{tabularx}}
	\item{\begin{tabularx}{\textwidth}{ X X X }   
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
		 $MOVE(C, Table, B)$& $OnTable(C)$	& $Clear(C)$\\  	
		$On(C,B)$		&        $Clear(C)$		& $OnTable(A)$\\	
							& 		$Clear(B)$		& $Clear(B)$\\					
		 					& 							& $On(B, A)$\\	
		 					& 							& $OnTable(C)$\\		 						
	\end{tabularx}}
	\item{\begin{tabularx}{\textwidth}{ X X X }  
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
		$On(C,B)$ 		&$MOVE(C, Table, B)$	& $Clear(C)$\\  	
							&       						& $OnTable(A)$\\	
							& 							& $\cancel{Clear(B)}$\\					
		 					& 							& $On(B, A)$\\	
		 					& 							& $\cancel{OnTable(C)}$\\		 						
		 					& 							& $On(C,B)$\\
		 					& 							& $Clear(Table)!$\\		 							 					
	\end{tabularx}}
	\item{\begin{tabularx}{\textwidth}{ X X X }  
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
		$Done!$			&$On(C, B)$				& $Clear(C)$\\  	
							&       						& $OnTable(A)$\\	
							& 							& $On(C, B)$\\					
		 					& 							& $On(B, A)$\\	
		 					& 							& $Clear(Table)$\\		 						
	\end{tabularx}}
\end{enumerate}
%\end{multicols}
\clearpage
\subsection{Demonstrate the Sussman Anomaly}
There are three ways of ordering the sub-goals $On(A, B), On(B, C), OnTable(C)$ in this scenario which could cause
Sussman's Anomaly:

\begin{tabularx}{\textwidth}{ X X X } 
$On(B, C)$  		&  $On(B, C)$  		& $OnTable(C)$ \\
$OnTable(C)$  	&  $On(A, B)$  		& $On(A, B)$ \\
$On(A, B)$  		&  $OnTable(C)$  	& $On(B, C)$ \\
\end{tabularx}

An illustration of the first of these stacks follows:

\begin{enumerate}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
   	\setlength{\parsep}{0pt} 
	\item{\begin{tabularx}{\textwidth}{ X X X } 
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
		$On(B, C)$ 		& 							& $On(C, A)$\\  	
		$OnTable(C)$	& 							& $OnTable(A)$\\	
		$On(A, B)$		& 							& $OnTable(B)$\\					
		 					& 							& $Clear(B)$\\
		 					& 							& $Clear(C)$\\
	\end{tabularx}}
	\item{\begin{tabularx}{\textwidth}{ X X X } 
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
	$MOVE(B, Table, C)$& 							& $On(C, A)$\\  	
		$On(B, C)$		& 							& $OnTable(A)$\\	
		$OnTable(C)$	& 							& $OnTable(B)$\\					
		$On(A, B)$		& 							& $Clear(B)$\\
		 					& 							& $Clear(C)$\\
	\end{tabularx}}
	\item{\begin{tabularx}{\textwidth}{ X X X }  
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
		$Clear(B)$		& 							& $On(C, A)$\\  	
		$Clear(C)$		& 							& $OnTable(A)$\\	
		$OnTable(B)$	& 							& $OnTable(B)$\\					
	$MOVE(B, Table, C)$& 							& $Clear(B)$\\
		 $On(B, C)$		& 							& $Clear(C)$\\	
		 $OnTable(C)$	& 							& \\
		$On(A, B)$		& 							& \\		 					
	\end{tabularx}}
	\item{\begin{tabularx}{\textwidth}{ X X X } 
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
	$MOVE(B, Table, C)$& 		$OnTable(B)$	& $On(C, A)$\\  	
		$On(B, C)$		& 		$Clear(C)$		& $OnTable(A)$\\	
		$OnTable(C)$	& 		$Clear(B)$		& $OnTable(B)$\\					
		$On(A, B)$		& 							& $Clear(B)$\\
		 					& 							& $Clear(C)$\\
	\end{tabularx}}
	\item{\begin{tabularx}{\textwidth}{ X X X } 
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
		$On(B, C)$		& $MOVE(B, Table, C)$	& $On(C, A)$\\  	
		$OnTable(C)$	& 							& $OnTable(A)$\\	
		$On(A, B)$		& 							& $\cancel{OnTable(B)}$\\					
							& 							& $Clear(B)$\\
		 					& 							& $\cancel{Clear(C)}$\\
		 					& 							& $On(B, C)$\\		 					
	\end{tabularx}}
	\item{\begin{tabularx}{\textwidth}{ X X X } 
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
		$OnTable(C)$	& 		$On(B, C)$		& $On(C, A)$\\  	
		$On(A, B)$		& 							&  $On(B, C)$\\
							& 							& $OnTable(A)$\\					
							& 							& $Clear(B)$\\ 					
	\end{tabularx}}
	\item{\begin{tabularx}{\textwidth}{ X X X } 
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
$MOVE-TO-TABLE(C)$	& 							& $On(C, A)$\\  	
		$OnTable(C)$	& 							&  $On(B, C)$\\
		$On(A, B)$		& 							& $OnTable(A)$\\					
							& 							& $Clear(B)$\\ 					
	\end{tabularx}}
	\item{\begin{tabularx}{\textwidth}{ X X X } 
		\textbf{goal-stack} & \textbf{popped} & \textbf{KB}\\  	
		$Clear(C)$		& 							& $On(C, A)$\\  	
		$On(C, A)$		& 							&  $On(B, C)$\\
$MOVE-TO-TABLE(C, A)$& 						& $OnTable(A)$\\					
		$OnTable(C)$	& 							& $Clear(B)$\\ 					
		$On(A, B)$		& 							& \\ 								
	\end{tabularx}}
\end{enumerate}
And now we can't proceed with the second sub-goal without undoing the first (which is no longer on the stack)!

%------------------------ Q2 ------------------------%
\section{Context free grammars for English}
\subsection{sentences parsed by the given grammar}
For the proposed grammar, a noun can be composed in two ways and is included twice in a sentence. Thus, the given grammar could parse/generate $2\times2 = 4$ sentences:
\begin{itemize}
\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
    	\setlength{\parsep}{0pt} 
	\item{the computer crashes the computer}
	\item{the computer crashes the program}
	\item{the program crashes the computer}
	\item{the program crashes the program}	
\end{itemize}
\subsection{enhance the grammar to parses/generates NPs with modifiers}
If we wanted to parse NPs that included a complement \emph{that}
\footnote{ie. np $\rightarrow$ det noun $|$ det adj noun $|$ det noun compl $|$ det adj noun compl }, 
we would run into all sorts of trouble by possibly generating/parsing sentences such as \textit{the program that crashes the computer that}.
Instead, by modifying rules 1 and 2, the grammar could still parse sentences such as \textit{the bad program that 
crashes the computer}.
The necessary modifications are listed below.  
	\renewcommand{\labelenumi}{\roman{enumi}}   
\begin{enumerate}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
    	\setlength{\parsep}{0pt} 
	\item{\makebox[2cm]{sentence\hfill}$\longrightarrow$ np vp $|$ np compl vp}
	\item{\makebox[2cm]{np\hfill}$\longrightarrow$ det noun $|$ det adj noun}
	\item{\makebox[2cm]{vp\hfill}$\longrightarrow$ verb np}
	\item{\makebox[2cm]{noun\hfill}$\longrightarrow$ computer $|$ program}
	\item{\makebox[2cm]{verb\hfill}$\longrightarrow$ crashes}
	\item{\makebox[2cm]{det\hfill}$\longrightarrow$ the}
	\item{\makebox[2cm]{adj\hfill}$\longrightarrow$ fast $|$ bad}
	\item{\makebox[2cm]{compl\hfill}$\longrightarrow$ that}
\end{enumerate}
The series of parsed/generated sentences grows considerably, since we can now generate sentences in two different ways and nouns in $2\times 3 = 6$ ways. Since we have two nouns in the sentence then we have $2\times 2 \times 3 \times 2 \times 3 = 72$ sentences: 
\\

\begin{multicols}{2}
\renewcommand\labelitemi{}
\begin{itemize}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
    	\setlength{\parsep}{0pt} 
    	    	\small{
	\item{the computer crashes the computer}
	\item{the computer crashes the program}
	\item{the program crashes the computer}
	\item{the program crashes the program}
	\item{}
	\item{the computer that crashes the computer}
	\item{the computer that crashes the program}
	\item{the program that crashes the computer}
	\item{the program that crashes the program}	
	\item{}	
	\item{the fast computer crashes the computer}
	\item{the fast computer crashes the program}
	\item{the fast program crashes the computer}
	\item{the fast program crashes the program}
	\item{}	
	\item{the fast computer that crashes the computer}
	\item{the fast computer that crashes the program}
	\item{the fast program that crashes the computer}
	\item{the fast program that crashes the program}	
	\item{}	
	\item{the bad computer crashes the computer}
	\item{the bad computer crashes the program}
	\item{the bad program crashes the computer}
	\item{the bad program crashes the program}
	\item{}	
	\item{the bad computer that crashes the computer}
	\item{the bad computer that crashes the program}
	\item{the bad program that crashes the computer}
	\item{the bad program that crashes the program}	
	%------------------%
	\item{}
	\item{the computer crashes the fast computer}
	\item{the computer crashes the fast program}
	\item{the program crashes the fast computer}
	\item{the program crashes the fast program}
	\item{}	
	\item{the computer that crashes the fast computer}
	\item{the computer that crashes the fast program}
	\item{the program that crashes the fast computer}
	\item{the program that crashes the fast program}	
	\item{}	
	\item{the fast computer crashes the fast computer}
	\item{the fast computer crashes the fast program}
	\item{the fast program crashes the fast computer}
	\item{the fast program crashes the fast program}
	\item{}	
	\item{the fast computer that crashes the fast computer}
	\item{the fast computer that crashes the fast program}
	\item{the fast program that crashes the fast computer}
	\item{the fast program that crashes the fast program}	
	\item{}	
	\item{the bad computer crashes the fast computer}
	\item{the bad computer crashes the fast program}
	\item{the bad program crashes the fast computer}
	\item{the bad program crashes the fast program}
	\item{}	
	\item{the bad computer that crashes the fast computer}
	\item{the bad computer that crashes the fast program}
	\item{the bad program that crashes the fast computer}
	\item{the bad program that crashes the fast program}	
	%------------------%
	\item{}
	\item{the computer crashes the bad computer}
	\item{the computer crashes the bad program}
	\item{the program crashes the bad computer}
	\item{the program crashes the bad program}
	\item{}	
	\item{the computer that crashes the bad computer}
	\item{the computer that crashes the bad program}
	\item{the program that crashes the bad computer}
	\item{the program that crashes the bad program}	
	\item{}	
	\item{the fast computer crashes the bad computer}
	\item{the fast computer crashes the bad program}
	\item{the fast program crashes the bad computer}
	\item{the fast program crashes the bad program}
	\item{}	
	\item{the fast computer that crashes the bad computer}
	\item{the fast computer that crashes the bad program}
	\item{the fast program that crashes the bad computer}
	\item{the fast program that crashes the bad program}	
	\item{}	
	\item{the bad computer crashes the bad computer}
	\item{the bad computer crashes the bad program}
	\item{the bad program crashes the bad computer}
	\item{the bad program crashes the bad program}
	\item{}	
	\item{the bad computer that crashes the bad computer}
	\item{the bad computer that crashes the bad program}
	\item{the bad program that crashes the bad computer}
	\item{the bad program that crashes the bad program}	
	\item{} 
		} % end small
\end{itemize}
\end{multicols}
Out of all these syntactically correct sentences, there are several which make little sense. Although a faulty computer
 might cause a program to crash, this is not generally understood to be the case. Also, potentially one computer 
might crash another computer\footnote{\ldots by running a red light. Sorry, couldn't help it.} in some form of networked
 situation, in general it is programs that crash computers or maybe even other programs running synchronously. However,
 in the case of a program crashing \emph{another} program, we would generally require some specifier to distinguish 
 between programs (eg `this program crashed the other program'). 
 
 Another thing that makes little sense is qualifying a computer as `bad', where it makes perfect sense for a program (specially 
 one that causes computers to crash.
 
 This leaves only a small subset of the language that really makes sense:
 \begin{multicols}{2}
\renewcommand\labelitemi{}
 \begin{itemize}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
    	\setlength{\parsep}{0pt} 
    	    	\small{
 	\item{the program crashes the computer}
	\item{the program crashes the fast computer}
	\item{the program that crashes the computer}
	\item{the program that crashes the fast computer}
	\item{the bad program crashes the computer}
	\item{the bad program crashes the fast computer}
	\item{the bad program that crashes the computer}
	\item{the bad program that crashes the fast computer}
	\item{the fast program crashes the computer}
	\item{the fast program crashes the fast computer}
	\item{the fast program that crashes the computer}
	\item{the fast program that crashes the fast computer}
	} % end small
\end{itemize}
\end{multicols}

\clearpage

The necessary modifications could easily be made  by using a context-sensitive grammar but are not as natural 
to a context-free grammar.
 \begin{enumerate}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
    	\setlength{\parsep}{0pt} 
	\item{\makebox[3cm]{sentence\hfill}$\longrightarrow$ np vp $|$ np compl vp}
	\item{\makebox[3cm]{np\hfill}$\longrightarrow$ det noun $|$ det adj noun}
	\item{\makebox[3cm]{vp\hfill}$\longrightarrow$ verb np}
	\item{\makebox[3cm]{noun vp\hfill}$\longrightarrow$ program vp}
	\item{\makebox[3cm]{adj noun vp\hfill}$\longrightarrow$ bad program vp $|$ fast program vp}
	\item{\makebox[3cm]{verb det noun\hfill}$\longrightarrow$ verb det computer}
	\item{\makebox[3cm]{verb det adj noun\hfill}$\longrightarrow$ verb det fast computer}
	\item{\makebox[3cm]{verb\hfill}$\longrightarrow$ crashes}
	\item{\makebox[3cm]{det\hfill}$\longrightarrow$ the}
	\item{\makebox[3cm]{compl\hfill}$\longrightarrow$ that}
\end{enumerate}

Where in a context-free grammar we would have to use something like the following grammar, which can quickly 
become unwieldy:
	\renewcommand{\labelenumi}{\roman{enumi}}   
\begin{enumerate}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
    	\setlength{\parsep}{0pt} 
	\item{\makebox[2cm]{sentence\hfill}$\longrightarrow$ np vp $|$ np compl vp}
	\item{\makebox[2cm]{np\hfill}$\longrightarrow$ det noun $|$ det adj noun}
	\item{\makebox[2cm]{vp\hfill}$\longrightarrow$ verb det obj $|$ verb det obj-adj obj}
	\item{\makebox[2cm]{noun\hfill}$\longrightarrow$ program}
	\item{\makebox[2cm]{obj\hfill}$\longrightarrow$ computer}
	\item{\makebox[2cm]{verb\hfill}$\longrightarrow$ crashes}
	\item{\makebox[2cm]{det\hfill}$\longrightarrow$ the}
	\item{\makebox[2cm]{adj\hfill}$\longrightarrow$ fast $|$ bad}
	\item{\makebox[2cm]{obj-adj\hfill}$\longrightarrow$ fast}
	\item{\makebox[2cm]{compl\hfill}$\longrightarrow$ that}
\end{enumerate}
 
%------------------------ Q3 ------------------------%
\section{A*}
\subsection{BFS expansion}
\renewcommand\labelitemi{}
\begin{itemize}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
    	\setlength{\parsep}{0pt} 
	\item{\makebox[4cm]{\textbf{closed list}\hfill}\textbf{open list}}
	\item{\makebox[4cm]{\hfill}S-11}
	\item{\makebox[4cm]{S\hfill}D-8.9, A-10.4}	
	\item{\makebox[4cm]{SD\hfill}E-6.9, A-10.4}
	\item{\makebox[4cm]{SDE\hfill}F-3, B-6.7, A-10.4}
	\item{\makebox[4cm]{SDEF\hfill}G-0, B-6.7, A-10.4}
	\item{\makebox[4cm]{SDEFG\hfill}B-6.7, A-10.4 --- \textbf{Done!}} 
\end{itemize}


\subsection{A* expansion}
\renewcommand\labelitemi{}
\begin{itemize}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
    	\setlength{\parsep}{0pt} 
	\item{\makebox[4cm]{\textbf{closed list}\hfill}\makebox[2cm]{\textbf{accrued}\hfill}\textbf{open list}}
	\item{\makebox[4cm]{\hfill}\makebox[2cm]{0\hfill}S-11+0}
	\item{\makebox[4cm]{S\hfill}\makebox[2cm]{0\hfill}D-8.9+4, A-10.4+3}	
	\item{\makebox[4cm]{SD\hfill}\makebox[2cm]{4\hfill}E-6.9+6, A-10.4+3}
	\item{\makebox[4cm]{SDE\hfill}\makebox[2cm]{6\hfill}F-3+10, A-10.4+3, B-6.7+11}
	\item{\makebox[4cm]{SDEF\hfill}\makebox[2cm]{10\hfill}G-0+13, A-10.4+3, B-6.7+11}
	\item{\makebox[4cm]{SDEFG\hfill}\makebox[2cm]{13\hfill}A-10.4+3, B-6.7+11 --- \textbf{Done!}} 
\end{itemize}



%------------------------ Q4 ------------------------%
\section{Decision tree}
From the table we are given, we can derive the entropy of our observations for the two possible outcomes $sunburnt = \{0,1\}$ .
\[
H[sunburned] = -\frac{3}{8}log_2(\frac{3}{8}) -\frac{5}{8}log_2(\frac{5}{8}) = 0.95443
\]
Information gain, $IG(x, y) = H[x] - \sum_y p(y)H[x|y]$ requires calculating conditional entropies given each one of the features.
For names, since we have no repeated names, each name is associated with a single outcome, which implies that the entropy of sunburned \emph{given} a certain name will be 0 for these observations.
\begin{equation*}
\begin{aligned}
H[sunburned | Name] =& \sum\limits_n p(sunburned|Name=n)H[sunburned|Name=n]\\
                                 =& \sum\limits_n \frac{1}{8} \cdot 0\\
IG(sunburned, Name) =& H[sunburned] - 0 = 0.954434002924965
\end{aligned}
\end{equation*}
Which would make $Name$ an obvious choice for the tree, given the sole $IG$ criterion for deciding, since we have maximal information gain (which is not the case for any other feature).
\\

\begin{forest} [Name 
						[Sarah [\textit{sunburned} ]]
		               		[Dana  [\textit{none} ]]
           		    		[Alex   [\textit{none} ]]
               				[Annie [\textit{sunburned} ]]
               				[Emily  [\textit{sunburned} ]]
              		 		[Pete   [\textit{none} ]]
               				[John  [\textit{none} ]]
               				[Katie  [\textit{none} ]]
				]
\end{forest}
\\

It must be noted, however, that yielding one leaf per observation is generally due to a poor choice of feature leading
 to over-fitting, and representative of the high variance typical of decision trees. This decision tree does not generalize well.
 
 If, however, we decided to go with the next-highest information gain, Then we would need to compare information gains for
  other features. Firstly hair, out of 8 observations there are 4 blonds, 3 brown-haired and 1 red-haired. From the 4 blondes, 
  half were sunburned, half were not. For both brown-haired and red-haired, entropy is $0$ since they each represent a single 
  class.
 \begin{equation*}
\begin{aligned}
H[sb | Hr] =& \sum\limits_h p(sb|Hr=h)H[sb|Hr=h]\\
                                 =& p(sb|Hr=bl)H[sb|Hr=bl] + p(sb|Hr=r)H[sb|Hr=r]
                                 + p(sb|Hr=br)H[sb|Hr=br]\\
                                 =& -\frac{1}{2} \cdot \cancel{2 \cdot \frac{1}{2}}log_2\left(\frac{1}{2}\right) + 0 + 0\\
                                 =& 0.5\\
	IG(sb, Hr) =& H[sb] - 0.5 = 0.45443
\end{aligned}
\end{equation*}
Considering height, there are average, tall and short people in the observations. Out of 3 average subjects, 2 were sunburned.
There were 2 tall, none sunburned and 3 short of whom 1 was sunburned.
 \begin{equation*}
\begin{aligned}
H[sb | Ht] =& \sum\limits_ht p(sb|Ht=ht)H[sb|Ht=ht]\\
                                 =& p(sb|Ht=avg)H[sb|Ht=avg] + p(sb|Ht=t)H[sb|Ht=t]
                                 + p(sb|Ht=sh)H[sb|Ht=sh]\\
                                 =& -2 \cdot \frac{3}{8} \cdot  \left( \frac{2}{3}log_2\left(\frac{2}{3}\right) 
                                 + \frac{1}{3}log_2\left(\frac{1}{3}\right) \right)
                                 + 0\\
                                 =& 0.34436\\
	IG(sb, Ht) =& H[sb] - 0.68872 =0.26571
\end{aligned}
\end{equation*}
Considering weight, there are average, heavy and light people in the observations. Out of 3 average subjects, 1 was
 sunburned. From the 2 light, 1 was sunburned and from the 3 heavy, 1 was sunburned.
 \begin{equation*}
\begin{aligned}
H[sb | W] =& \sum\limits_w p(sb|W=w)H[sb|W=w]\\
                                 =& p(sb|W=avg)H[sb|W=avg] + p(sb|W=h)H[sb|W=h]
                                 + p(sb|W=l)H[sb|W=l]\\
                                 =& -2 \cdot \frac{3}{8} \cdot  \left( \frac{2}{3}log_2\left(\frac{2}{3}\right) 
                                 + \frac{1}{3}log_2\left(\frac{1}{3}\right) \right)
                                 + \left( -\frac{2}{8} \cdot \cancel{2 \cdot \frac{1}{2}}log_2\left(\frac{1}{2}\right) \right)\\
                                 =& 0.93872\\
	IG(sb, W) =& H[sb] - 0.93872 = 0.01571
\end{aligned}
\end{equation*}
Considering the use of lotion, 3 people used lotion and were not sunburned, having an entropy of 0. Out of the remaining 5 subjects, 3 were
 sunburned and 2 were not.
 \begin{equation*}
\begin{aligned}
H[sb | L] =& \sum\limits_w p(sb|L=l)H[sb|L=l]\\
                                 =& p(sb|L=y)H[sb|L=y] + p(sb|L=n)H[sb|L=n]\\
                                 =& -\frac{5}{8} \cdot  \left( \frac{2}{5}log_2\left(\frac{2}{5}\right) 
                                 + \frac{3}{5}log_2\left(\frac{3}{5}\right) \right)\\
                                 =&0.60684\\
	IG(sb, L) =& H[sb] - 0.60684 =0.34758
\end{aligned}
\end{equation*}

From which we see that hair color is a good discriminant for being sunburned. Brown-haired and red-haired have 0 entropy and
blonds have 2 cases of sunburns. Quickly checking the features, we can see that the use of lotion as a second decision 
correctly classifies all cases, having the highest information gain, since other features do not have total information gain.
The tree, therefore, would end up like this:
\\
\begin{center}
\begin{forest} [Hair
						[Blond [Lotion?
							[N - \textit{sunburned} ]
							[Y - \textit{none} ]]]
		               		[Red  [\textit{Sunburned} ]]
           		    		[Brown   [\textit{none} ]]
				]
\end{forest}
\end{center}
\clearpage

%------------------------ Q5 ------------------------%
\section{Genetic Algorithms}
I have actually implemented this out of curiosity and have included it at the end of this assignment as well as the code.
\subsection{defining a gene representation}
We propose using 5 hexadecimal digits, in the form $a^n + b \sqrt{c^m}, \mid a, b, m, n \in \{-15, -14, \ldots 14, 15\}, c \in \{0, 1,\ldots 15\}$. Internally, it is essentially a list \texttt{(a, b, c, m, n)}.

\subsection{fitness function}
The fitness function could be $\frac{1}{l}$ where for the number $\hat{x}$ resulting from the expansion of the model, and the 
expression $f(x)=x^2 + 2x - 11$, we have $l = |f(x) - f(\hat{x})|$ or otherwise, simply $l = |f(\hat{x})|$. Instead of 
implementing a fitness function, I have simply used the loss function.

\subsection{crossover and mutation - 2 generations for a small initial population of 8}
I have defined the behavior as follows:
\begin{itemize}
	\setlength{\itemsep}{0pt}
	\setlength{\parskip}{0pt}
    	\setlength{\parsep}{0pt} 
	\item The population is constantly 8 models
	\item The initial values of the first 8 models are chosen with uniform probability given respective range constraints\footnote{Additional constraints such as \texttt{if c == 0 then m = 1} to avoid divide-by-zero errors.}
	\item The four fittest parents remain
	\item The four pairs to be recombined are chosen randomly with repetition
	\item For each offspring, $a, b, c$ are taken from $parent_1$ with added rounded-off $N(0, 2)$, constraining 
	values to their respective range
	\item For each offspring, $m, n$ are taken from $parent_2$ with added rounded-off $N(0, 2)$, constraining 
	values to their respective range
	\item $l$ is recomputed \ldots
\end{itemize}

Here are 8 models during 2 generations:
\begin{verbatim}
	1st generation	
		(c^4) + 5*sqrt(7^0)					loss - 430230552.0
		(f^3) + -9*sqrt(b^1)					loss - 11196710.344739685
		(-6^4) + -f*sqrt(2^2)					loss - 1605277.0
		(-8^2) + -b*sqrt(7^2)					loss - 184.0
		(6^-3) + -6*sqrt(0^1)					loss - 10.990719307270233
		(-b^2) + -d*sqrt(3^2)					loss - 6877.0
		(b^0) + f*sqrt(8^2)					loss - 14872.0
		(3^1) + b*sqrt(1^1)					loss - 213.0
	2nd generation
		(6^-3) + -6*sqrt(0^1)					loss -10.99071930727023
		(-8^2) + -b*sqrt(7^2)					loss -184.0
		(3^1) + b*sqrt(1^1)					loss -213.0
		(-b^2) + -d*sqrt(3^2)					loss -6877.0
		(-7^2) + -d*sqrt(9^3)					loss -91797.0
		(3^3) + -8*sqrt(1^5)					loss -388.0	
		(-d^3) + -f*sqrt(1^-2)					loss -4897357.		
		(5^-3) + b*sqrt(1^2)					loss -132.192064
\end{verbatim}

\subsection{explain the state space - convergence?}
The state space is comprised of the set of real numbers. The solution to the sample expression is actually an irrational number, 
from which follows that the algorithm will not converge entirely since the computer's floating-point representation 
cannot represent an irrational number, however the algorithm could tend to approximate this number quite well. I the 
environment in which I ran this, it approximates to within slightly less than a loss of $1.78e-15$. Given this slack definition of convergence for the problem at hand, I ran the GA 16 times for the 16 times it converged in the number of iterations shown below.

\begin{verbatim}
	converged in  839
	converged in  153
	converged in  2570
	converged in  169
	converged in  32
	converged in  23431
	converged in  1639
	converged in  308
	converged in  159
	converged in  2774
	converged in  64
	converged in  1609
	converged in  1847
	converged in  1395
\end{verbatim}

\subsection{how might GA's solve this? Preferable to brute force search?}
A despite the one-dimensional solution to the problem, since we're trying to find something in an infinite space, a brute force
search would be very difficult. We would need to \emph{tune} the brute-force search with the right parameters to make it work;
essentially we have granularity, search-direction\footnote{Or an algorithm for jumping around in its stead.} and bounds that need to be decided; this could be seen like a 3 dimensional problem. With an informed search, this could be achieved very quickly, but a brute-force search could very well not converge. GA's are slower than a proper informed search but they tend to converge, as does this example, given the representational constraints; this makes them preferable to brute-force-search
in itself. 

\subsection{Appendix - code for \texttt{test\textunderscore gen.py}}

\lstinputlisting[breaklines]{test_gen.py}

\end{document} 